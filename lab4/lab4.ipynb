{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+-----------+----------+-----+\n",
      "|review_text|             summary|        profile_name|helpfulness|      time|score|\n",
      "+-----------+--------------------+--------------------+-----------+----------+-----+\n",
      "|       null|\"There Is So Much...|Brian E. Erland \"...|        7/7|1182729600|  3.0|\n",
      "|       null|Worthwhile and Im...|          Grady Harp|        4/4|1181952000|  3.0|\n",
      "|       null|This movie needed...|Chrissy K. McVay ...|       8/10|1164844800|  5.0|\n",
      "|       null|distantly based o...|        golgotha.gov|        1/1|1197158400|  3.0|\n",
      "|       null|\"What's going on ...|KerrLines \"&#34;M...|        1/1|1188345600|  3.0|\n",
      "|       null|Pretty pointless ...|abra \"a devoted r...|        0/0|1229040000|  2.0|\n",
      "|       null|This is junk, sta...| Charles R. Williams|       3/11|1164153600|  1.0|\n",
      "|       null|A  Rock N Roll Hi...|   Anthony Accordino|      64/65|1060473600|  5.0|\n",
      "|       null|A  MUST-HAVE  vid...|    Joseph P. Aiello|      26/26|1041292800|  5.0|\n",
      "|       null|If You Like DooWo...|     \"bruce_from_la\"|      24/24|1061164800|  5.0|\n",
      "|       null|    I expected more.|    Henrique Peirano|      22/23|1039564800|  4.0|\n",
      "|       null|Professional Exce...|      Richard Albero|      14/14|1045526400|  5.0|\n",
      "|       null|Marvelous, just M...|                 Les|        9/9|1062979200|  5.0|\n",
      "|       null|Pittsburgh - Home...|     Joseph M. Kotow|        9/9|1042502400|  5.0|\n",
      "|       null|They sang in the ...|      \"fellafromnyc\"|        7/7|1049846400|  4.0|\n",
      "|       null|DOO WOP RECORDED ...|           S. Dorman|        7/7|1047945600|  5.0|\n",
      "|       null|ROCK RYTHM AND DO...|                 RFP|        7/7|1038787200|  5.0|\n",
      "|       null|Unbelievable Best...|           C. Thomas|        4/4|1177804800|  5.0|\n",
      "|       null|Another outstandi...|   Michael A. Martin|        3/3|1200096000|  5.0|\n",
      "|       null|Outstanding Wheth...|C. W. Emblom \"Bil...|        5/6|1082592000|  5.0|\n",
      "+-----------+--------------------+--------------------+-----------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationSystem\").getOrCreate()\n",
    "\n",
    "# Define the schema for the dataset\n",
    "schema = StructType([\n",
    "    StructField(\"review_text\", StringType(), True),\n",
    "    StructField(\"summary\", StringType(), True),\n",
    "    StructField(\"profile_name\", StringType(), True),\n",
    "    StructField(\"helpfulness\", StringType(), True),\n",
    "    StructField(\"time\", StringType(), True),\n",
    "    StructField(\"score\", DoubleType(), True),\n",
    "])\n",
    "\n",
    "# Path to your JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "\n",
    "# Load the JSON data into a PySpark DataFrame\n",
    "recommendation_df = spark.read.json(json_file_path, schema=schema)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "recommendation_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+\n",
      "|       user_id|product_id| prediction|\n",
      "+--------------+----------+-----------+\n",
      "|A13RM1AWD1C5ZR|B0001G6PZC|-0.24127243|\n",
      "|A145CT70T2SB51|B0012EM5GK|  5.1345353|\n",
      "|A10X0JN8KTK89H|6304286961|  2.9998443|\n",
      "|A103EXN5Q7HX6Z|B0095D5454|        NaN|\n",
      "|A10X4NX66GHW49|B000063W82|        NaN|\n",
      "|A10XUPHLWRCGY4|B000063W82|        NaN|\n",
      "|A11977Q3OXQYHD|B00096S43U|        NaN|\n",
      "|A11IKZMXWDI763|B0001G6PZC|        NaN|\n",
      "|A122E0BU0KVYDA|B000063W82|        NaN|\n",
      "|A1250POFZL8U1B|B0001G6PZC|        NaN|\n",
      "|A13OMT8D4GPIBV|6304286961|        NaN|\n",
      "|A149KBE47CBLYD|B00004CQTP|        NaN|\n",
      "|A14LAZ5I1YD6I1|B0016OLXN2|        NaN|\n",
      "|A14MNXASHGYPN7|B000063W82|        NaN|\n",
      "|A14N5L5T089VX3|0800103688|        NaN|\n",
      "|A12MRCRQV18FEQ|B002OHDRF2| 0.99803513|\n",
      "|A13TO1ZFAH9SVN|B000063W1R|  7.6159043|\n",
      "|A141HP4LYPWMSR|B000063W1R|-0.73775494|\n",
      "|A10DB0H2NZF11E|B002OHDRF2|  4.9901752|\n",
      "|A13IKSGDYNBNQS|B0001G6PZC| -0.3449365|\n",
      "+--------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"user_id\", \"product_id\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|       user_id|product_id|prediction|\n",
      "+--------------+----------+----------+\n",
      "|A137AX2DG2D3QD|B002OHDRF2| 1.9686402|\n",
      "|A127PCLKOSDS04|B000UGBOT0| 1.1798981|\n",
      "|A133CUOCQTPKTT|B002OHDRF2| 2.9810488|\n",
      "|A12X8OWP4N74KP|B0001G6PZC| 1.0251399|\n",
      "|A100Y8WSLFJN7Q|B000063W1R|       NaN|\n",
      "|A103EXN5Q7HX6Z|B0095D5454|       NaN|\n",
      "|A103ZG6ASSR7UT|B004TWOX26|       NaN|\n",
      "|A1041HQGJDKFG5|B0001G6PZC|       NaN|\n",
      "|A10GI7HCPT27SZ|0800103688|       NaN|\n",
      "|A110UAX71H8R0W|0790747324|       NaN|\n",
      "|A11HMB8Z48EV76|B0001G6PZC|       NaN|\n",
      "|A11JC53JUZ0TBK|B000063W82|       NaN|\n",
      "|A11NH0A73VNNA6|6304286961|       NaN|\n",
      "|A11R16C1ZKEWOI|0800103688|       NaN|\n",
      "|A11SMJ2SH7OAR7|B006FYGF8Q|       NaN|\n",
      "|A12FDY8QMUW9V5|B000UGBOT0|       NaN|\n",
      "|A12Q0LLN5R2XAG|B002OHDRF2|       NaN|\n",
      "|A12SX8D30RZ6QF|B0001G6PZC|       NaN|\n",
      "|A12V5I7WHOYXVK|0790747324|       NaN|\n",
      "|A13547L1PPP0OP|B000063W82|       NaN|\n",
      "+--------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"user_id\", \"product_id\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 5.178928544801977\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Check for missing or NaN values in the 'score' column\n",
    "df = df.dropna(subset=[\"score\"])\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Create an ALS (Alternating Least Squares) recommendation model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_index\", itemCol=\"product_index\", ratingCol=\"score\")\n",
    "\n",
    "# Create a pipeline to execute the indexers and ALS model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, als])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Check for NaN values in the 'prediction' column\n",
    "predictions = predictions.dropna(subset=[\"prediction\"])\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"score\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1.2578639101786042\n",
      "+--------------+----------+------------------+\n",
      "|       user_id|product_id|        prediction|\n",
      "+--------------+----------+------------------+\n",
      "|A103EXN5Q7HX6Z|B0095D5454| 4.280162584897461|\n",
      "|A1041HQGJDKFG5|B0001G6PZC| 4.305241120296268|\n",
      "|A1078L9AXZRGT7|B000063W82| 4.306244261712219|\n",
      "|A10X5D8JIK3QMS|B001GBPZRU| 3.999015879981755|\n",
      "|A10XHOI86O75LH|B00022VM5S| 3.959491712264729|\n",
      "|A11ED8O95W2103|B000063W82| 4.091157626453714|\n",
      "|A11JC53JUZ0TBK|B000063W82| 4.306244261712219|\n",
      "|A11NH0A73VNNA6|6304286961| 4.278156302065557|\n",
      "|A11PZ6HSK13L66|B00020HBNC| 3.959826092736713|\n",
      "|A11R16C1ZKEWOI|0800103688| 4.072405235748979|\n",
      "|A134K1N1C8VC37|6300147967| 4.221980382772231|\n",
      "|A13BLSXL78EMRX|0790747324| 4.286515813865159|\n",
      "|A13D1WTFEMS9VH|B00022VM5I| 4.056087851886209|\n",
      "|A13OMT8D4GPIBV|6304286961| 4.072181195053247|\n",
      "|A13RBXRUQ1LVAW|B000UGBOT0|4.2811657263134135|\n",
      "|A13RM1AWD1C5ZR|B0001G6PZC| 4.305241120296268|\n",
      "|A13RYD26OASOWN|B002OHDRF2| 4.120936612739646|\n",
      "|A13TO1ZFAH9SVN|B0001G6PZC| 4.090628370667588|\n",
      "|A13VU3KET33WG6|B0016OLXN2| 4.286181433393175|\n",
      "|A141HP4LYPWMSR|B000063W1R| 4.077881871253486|\n",
      "+--------------+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"RecommendationModel\").getOrCreate()\n",
    "\n",
    "# Read data from a JSON file\n",
    "json_file_path = \"movies.json\"\n",
    "df = spark.read.json(json_file_path)\n",
    "\n",
    "# Extract relevant columns for recommendation\n",
    "df = df.select(\"user_id\", \"product_id\", \"score\")\n",
    "\n",
    "# Convert user_id and product_id to numeric indices\n",
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
    "product_indexer = StringIndexer(inputCol=\"product_id\", outputCol=\"product_index\", handleInvalid=\"keep\")\n",
    "\n",
    "# Combine features into a feature vector\n",
    "feature_columns = [\"user_index\", \"product_index\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Create a linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"score\", maxIter=10, regParam=0.01)\n",
    "\n",
    "# Create a pipeline to execute the indexers, assembler, and linear regression model\n",
    "pipeline = Pipeline(stages=[user_indexer, product_indexer, assembler, lr])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "(training_data, test_data) = df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train the recommendation model\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Show the predictions\n",
    "predictions.select(\"user_id\", \"product_id\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
